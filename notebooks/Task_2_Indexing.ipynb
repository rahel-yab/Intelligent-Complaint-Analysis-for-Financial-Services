{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d50e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data from Task 1\n",
    "df_cleaned = pd.read_csv('data/processed/filtered_complaints.csv')\n",
    "\n",
    "# Create a stratified sample of 15,000 complaints\n",
    "sample_size = 15000\n",
    "df_sample = df_cleaned.groupby('product_category', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=int(len(x)/len(df_cleaned) * sample_size), random_state=42)\n",
    ")\n",
    "\n",
    "print(\"Sample distribution per product:\")\n",
    "print(df_sample['product_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a2b30",
   "metadata": {},
   "source": [
    "Text Chunking Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bcc296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# We use 500 characters with 50 character overlap\n",
    "# Overlap ensures that if a sentence is cut in half, the context is preserved in both chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "for _, row in df_sample.iterrows():\n",
    "    # Split the individual complaint\n",
    "    texts = text_splitter.split_text(row['cleaned_narrative'])\n",
    "    \n",
    "    # Create Document objects with metadata for tracing\n",
    "    for i, text in enumerate(texts):\n",
    "        chunks.append(Document(\n",
    "            page_content=text,\n",
    "            metadata={\n",
    "                \"complaint_id\": row.get('Complaint ID', 'N/A'),\n",
    "                \"product\": row['product_category'],\n",
    "                \"issue\": row.get('Issue', 'N/A'),\n",
    "                \"chunk_index\": i\n",
    "            }\n",
    "        ))\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(df_sample)} complaints.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
